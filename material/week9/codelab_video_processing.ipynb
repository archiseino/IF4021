{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on Sorting\n",
    "\n",
    "### Task 1\n",
    "Dari bagian kode ini:\n",
    "```python\n",
    "list_imgs = sorted(list_imgs, key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "print(f\"5 path pertama setelah diurutkan: {list_imgs[:5]}\")\n",
    "print(f\"Total jumlah gambar: {len(list_imgs)}\")\n",
    "```\n",
    "\n",
    "Kode ini bertujuan untuk mengurutkan (sorting) pada daftar gambar berdsarkan _key_ yang ditentukan dalam _lambda function_ seperti berikut.\n",
    "- `x.split('/')[-1]`, berfungsi untuk memisahkan string menjadi beberapa item dalam list, dan akan di ambil item terakhir.\n",
    "- `.split('.')[0]`, berfungsi untuk memisahkan item terakhir (berupa filename gambar) dan memisahkan filename dan extensi, lalu kita bisa mengambil filename sebagai key dalam proses konversi.\n",
    "- `int()`, berfungsi untuk mengkonvensi string menjadi nilai integer.\n",
    "\n",
    "Liat pada kasus ini, misalkan `list_imgs` berisi:\n",
    "```python\n",
    "list_imgs = ['path/to/image/1.jpg', 'path/to/image/10.jpg', 'path/to/image/2.jpg']\n",
    "```\n",
    "Proses untuk setiap item akan seperti berikut:\n",
    "1. Split `/`:\n",
    "`x.split('/')` akan memberikan `['path', 'to', 'image', '1.jpg']`\n",
    "2. Split `.`:\n",
    "`'1.jpg'.split('.')` akan menghasilkan daftar: ['1', 'jpg']\n",
    "Mengambil elemen pertama dengan [0]: `1`\n",
    "3. Konversi ke Integer:\n",
    "`int('1')` akan menghasilkan: 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Nafas\n",
    "| Nafas-ke | Second | Milisecond  |\n",
    "|----------|--------|-------------|\n",
    "|        1 |      7 |          89 |\n",
    "|        2 |     14 |          46 |\n",
    "|        3 |     19 |          67 |\n",
    "|        4 |     25 |          20 |\n",
    "|        5 |     30 |          10 |\n",
    "|        6 |     35 |          90 |\n",
    "|        7 |     40 |          77 |\n",
    "|        8 |     46 |          15 |\n",
    "|        9 |     50 |          86 |\n",
    "|       10 |     56 |          93 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precautionary Warnings\n",
    "When working with huge of images that makes up a video, instead of Video in general, take care on the number of images fremes you work up with. It can be a memory problem if you take a lot of images.\n",
    "> Warning!\n",
    "> Mungkin komputer Anda akan kehabisan memori jika jumlah gambar yang dijadikan video terlalu banyak. Jika hal ini terjadi, Anda bisa mengurangi jumlah gambar yang dijadikan video atau menggunakan komputer dengan spesifikasi yang lebih tinggi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the part code to set the seq of images to video frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_loc = os.path.join(os.getcwd(), 'data', 'toby-rgb.mp4')\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# height, width, layers = images_array[0].shape\n",
    "# video = cv2.VideoWriter(save_loc, fourcc, 30, (width, height))\n",
    "\n",
    "# for image in images_array:\n",
    "#     video.write(image)\n",
    "\n",
    "# video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Jelaskan tentang bagian kode berikut:\n",
    "```python\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "```\n",
    "\n",
    "Dalam `OpenCV`, `FOURCC` (Four Character Code) adalah 4-byte code yang digunakan untuk encoding / decoding dari sebuah video. Normalnya, setiap video containers memiliki format codec-nya sendiri seperti berikut:\n",
    "- XVID: MPEG-4 codec (often used for AVI files).\n",
    "- MJPG: Motion JPEG codec.\n",
    "- DIVX: DivX MPEG-4 codec.\n",
    "- H264: H.264 codec (requires additional software support).\n",
    "- MP4V: MPEG-4 codec for MP4 files.\n",
    "- I420: Uncompressed YUV format.\n",
    "\n",
    "Apa yang terjadi jika codec tidak sesuai dengan video container? Tidak ada kesalahan fatal, karena media player saat ini bisa mendukung berbagai macam codec, terlepas dari container format itu sendiri.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save frame from video into an images\n",
    "\n",
    "To save a sequence of images from a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set a Video Path and the Image Sequence path\n",
    "video_path = os.path.join(os.getcwd(), 'attachment', 'sample-renamed.mp4') \n",
    "image_sequence_path = os.path.join(os.getcwd(), 'data', 'image_sequence')\n",
    "\n",
    "## Create a folder if it does not exist\n",
    "if not os.path.exists(image_sequence_path):\n",
    "    os.makedirs(image_sequence_path)\n",
    "\n",
    "## Setup a videoCapture object and frame count\n",
    "videoCapture = cv2.VideoCapture(video_path)\n",
    "frame_count = 0\n",
    "\n",
    "## Read the video and save the frames for the first 100 frames\n",
    "while frame_count < 100:\n",
    "    ret, frame = videoCapture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imwrite(os.path.join(image_sequence_path, f'frame_{frame_count:03d}.png'), frame)\n",
    "    frame_count += 1\n",
    "\n",
    "## Release the videoCapture object\n",
    "videoCapture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Converting a video into lowest FPS video in grayscale, and with dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original FPS: 30.0\n",
      "Total Frames: 1800\n",
      "New FPS: 10.0\n",
      "Processed Frame 0: Red dot at (0, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 1: Red dot at (2, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 2: Red dot at (4, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 3: Red dot at (6, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 4: Red dot at (8, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 5: Red dot at (10, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 6: Red dot at (12, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 7: Red dot at (14, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 8: Red dot at (17, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 9: Red dot at (19, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 10: Red dot at (21, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 11: Red dot at (23, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 12: Red dot at (25, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 13: Red dot at (27, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 14: Red dot at (29, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 15: Red dot at (32, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 16: Red dot at (34, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 17: Red dot at (36, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 18: Red dot at (38, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 19: Red dot at (40, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 20: Red dot at (42, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 21: Red dot at (44, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 22: Red dot at (46, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 23: Red dot at (49, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 24: Red dot at (51, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 25: Red dot at (53, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 26: Red dot at (55, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 27: Red dot at (57, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 28: Red dot at (59, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 29: Red dot at (61, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 30: Red dot at (64, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 31: Red dot at (66, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 32: Red dot at (68, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 33: Red dot at (70, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 34: Red dot at (72, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 35: Red dot at (74, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 36: Red dot at (76, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 37: Red dot at (79, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 38: Red dot at (81, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 39: Red dot at (83, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 40: Red dot at (85, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 41: Red dot at (87, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 42: Red dot at (89, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 43: Red dot at (91, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 44: Red dot at (93, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 45: Red dot at (96, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 46: Red dot at (98, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 47: Red dot at (100, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 48: Red dot at (102, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 49: Red dot at (104, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 50: Red dot at (106, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 51: Red dot at (108, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 52: Red dot at (111, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 53: Red dot at (113, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 54: Red dot at (115, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 55: Red dot at (117, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 56: Red dot at (119, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 57: Red dot at (121, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 58: Red dot at (123, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 59: Red dot at (125, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 60: Red dot at (128, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 61: Red dot at (130, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 62: Red dot at (132, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 63: Red dot at (134, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 64: Red dot at (136, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 65: Red dot at (138, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 66: Red dot at (140, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 67: Red dot at (143, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 68: Red dot at (145, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 69: Red dot at (147, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 70: Red dot at (149, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 71: Red dot at (151, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 72: Red dot at (153, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 73: Red dot at (155, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 74: Red dot at (158, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 75: Red dot at (160, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 76: Red dot at (162, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 77: Red dot at (164, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 78: Red dot at (166, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 79: Red dot at (168, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 80: Red dot at (170, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 81: Red dot at (172, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 82: Red dot at (175, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 83: Red dot at (177, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 84: Red dot at (179, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 85: Red dot at (181, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 86: Red dot at (183, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 87: Red dot at (185, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 88: Red dot at (187, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 89: Red dot at (190, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 90: Red dot at (192, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 91: Red dot at (194, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 92: Red dot at (196, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 93: Red dot at (198, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 94: Red dot at (200, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 95: Red dot at (202, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 96: Red dot at (204, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 97: Red dot at (207, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 98: Red dot at (209, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 99: Red dot at (211, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 100: Red dot at (213, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 101: Red dot at (215, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 102: Red dot at (217, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 103: Red dot at (219, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 104: Red dot at (222, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 105: Red dot at (224, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 106: Red dot at (226, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 107: Red dot at (228, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 108: Red dot at (230, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 109: Red dot at (232, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 110: Red dot at (234, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 111: Red dot at (237, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 112: Red dot at (239, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 113: Red dot at (241, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 114: Red dot at (243, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 115: Red dot at (245, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 116: Red dot at (247, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 117: Red dot at (249, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 118: Red dot at (251, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 119: Red dot at (254, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 120: Red dot at (256, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 121: Red dot at (258, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 122: Red dot at (260, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 123: Red dot at (262, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 124: Red dot at (264, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 125: Red dot at (266, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 126: Red dot at (269, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 127: Red dot at (271, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 128: Red dot at (273, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 129: Red dot at (275, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 130: Red dot at (277, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 131: Red dot at (279, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 132: Red dot at (281, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 133: Red dot at (283, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 134: Red dot at (286, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 135: Red dot at (288, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 136: Red dot at (290, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 137: Red dot at (292, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 138: Red dot at (294, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 139: Red dot at (296, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 140: Red dot at (298, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 141: Red dot at (301, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 142: Red dot at (303, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 143: Red dot at (305, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 144: Red dot at (307, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 145: Red dot at (309, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 146: Red dot at (311, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 147: Red dot at (313, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 148: Red dot at (316, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 149: Red dot at (318, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 150: Red dot at (320, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 151: Red dot at (322, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 152: Red dot at (324, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 153: Red dot at (326, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 154: Red dot at (328, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 155: Red dot at (330, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 156: Red dot at (333, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 157: Red dot at (335, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 158: Red dot at (337, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 159: Red dot at (339, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 160: Red dot at (341, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 161: Red dot at (343, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 162: Red dot at (345, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 163: Red dot at (348, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 164: Red dot at (350, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 165: Red dot at (352, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 166: Red dot at (354, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 167: Red dot at (356, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 168: Red dot at (358, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 169: Red dot at (360, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 170: Red dot at (362, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 171: Red dot at (365, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 172: Red dot at (367, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 173: Red dot at (369, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 174: Red dot at (371, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 175: Red dot at (373, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 176: Red dot at (375, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 177: Red dot at (377, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 178: Red dot at (380, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 179: Red dot at (382, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 180: Red dot at (384, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 181: Red dot at (386, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 182: Red dot at (388, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 183: Red dot at (390, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 184: Red dot at (392, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 185: Red dot at (395, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 186: Red dot at (397, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 187: Red dot at (399, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 188: Red dot at (401, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 189: Red dot at (403, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 190: Red dot at (405, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 191: Red dot at (407, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 192: Red dot at (409, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 193: Red dot at (412, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 194: Red dot at (414, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 195: Red dot at (416, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 196: Red dot at (418, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 197: Red dot at (420, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 198: Red dot at (422, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 199: Red dot at (424, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 200: Red dot at (427, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 201: Red dot at (429, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 202: Red dot at (431, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 203: Red dot at (433, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 204: Red dot at (435, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 205: Red dot at (437, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 206: Red dot at (439, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 207: Red dot at (441, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 208: Red dot at (444, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 209: Red dot at (446, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 210: Red dot at (448, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 211: Red dot at (450, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 212: Red dot at (452, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 213: Red dot at (454, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 214: Red dot at (456, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 215: Red dot at (459, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 216: Red dot at (461, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 217: Red dot at (463, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 218: Red dot at (465, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 219: Red dot at (467, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 220: Red dot at (469, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 221: Red dot at (471, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 222: Red dot at (474, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 223: Red dot at (476, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 224: Red dot at (478, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 225: Red dot at (480, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 226: Red dot at (482, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 227: Red dot at (484, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 228: Red dot at (486, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 229: Red dot at (488, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 230: Red dot at (491, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 231: Red dot at (493, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 232: Red dot at (495, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 233: Red dot at (497, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 234: Red dot at (499, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 235: Red dot at (501, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 236: Red dot at (503, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 237: Red dot at (506, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 238: Red dot at (508, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 239: Red dot at (510, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 240: Red dot at (512, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 241: Red dot at (514, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 242: Red dot at (516, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 243: Red dot at (518, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 244: Red dot at (520, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 245: Red dot at (523, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 246: Red dot at (525, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 247: Red dot at (527, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 248: Red dot at (529, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 249: Red dot at (531, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 250: Red dot at (533, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 251: Red dot at (535, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 252: Red dot at (538, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 253: Red dot at (540, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 254: Red dot at (542, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 255: Red dot at (544, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 256: Red dot at (546, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 257: Red dot at (548, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 258: Red dot at (550, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 259: Red dot at (553, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 260: Red dot at (555, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 261: Red dot at (557, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 262: Red dot at (559, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 263: Red dot at (561, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 264: Red dot at (563, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 265: Red dot at (565, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 266: Red dot at (567, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 267: Red dot at (570, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 268: Red dot at (572, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 269: Red dot at (574, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 270: Red dot at (576, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 271: Red dot at (578, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 272: Red dot at (580, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 273: Red dot at (582, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 274: Red dot at (585, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 275: Red dot at (587, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 276: Red dot at (589, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 277: Red dot at (591, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 278: Red dot at (593, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 279: Red dot at (595, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 280: Red dot at (597, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 281: Red dot at (599, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 282: Red dot at (602, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 283: Red dot at (604, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 284: Red dot at (606, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 285: Red dot at (608, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 286: Red dot at (610, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 287: Red dot at (612, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 288: Red dot at (614, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 289: Red dot at (617, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 290: Red dot at (619, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 291: Red dot at (621, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 292: Red dot at (623, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 293: Red dot at (625, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 294: Red dot at (627, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 295: Red dot at (629, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 296: Red dot at (632, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 297: Red dot at (634, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 298: Red dot at (636, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 299: Red dot at (638, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 300: Red dot at (640, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 301: Red dot at (642, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 302: Red dot at (644, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 303: Red dot at (646, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 304: Red dot at (649, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 305: Red dot at (651, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 306: Red dot at (653, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 307: Red dot at (655, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 308: Red dot at (657, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 309: Red dot at (659, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 310: Red dot at (661, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 311: Red dot at (664, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 312: Red dot at (666, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 313: Red dot at (668, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 314: Red dot at (670, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 315: Red dot at (672, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 316: Red dot at (674, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 317: Red dot at (676, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 318: Red dot at (679, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 319: Red dot at (681, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 320: Red dot at (683, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 321: Red dot at (685, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 322: Red dot at (687, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 323: Red dot at (689, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 324: Red dot at (691, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 325: Red dot at (693, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 326: Red dot at (696, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 327: Red dot at (698, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 328: Red dot at (700, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 329: Red dot at (702, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 330: Red dot at (704, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 331: Red dot at (706, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 332: Red dot at (708, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 333: Red dot at (711, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 334: Red dot at (713, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 335: Red dot at (715, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 336: Red dot at (717, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 337: Red dot at (719, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 338: Red dot at (721, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 339: Red dot at (723, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 340: Red dot at (725, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 341: Red dot at (728, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 342: Red dot at (730, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 343: Red dot at (732, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 344: Red dot at (734, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 345: Red dot at (736, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 346: Red dot at (738, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 347: Red dot at (740, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 348: Red dot at (743, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 349: Red dot at (745, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 350: Red dot at (747, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 351: Red dot at (749, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 352: Red dot at (751, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 353: Red dot at (753, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 354: Red dot at (755, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 355: Red dot at (758, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 356: Red dot at (760, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 357: Red dot at (762, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 358: Red dot at (764, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 359: Red dot at (766, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 360: Red dot at (768, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 361: Red dot at (770, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 362: Red dot at (772, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 363: Red dot at (775, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 364: Red dot at (777, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 365: Red dot at (779, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 366: Red dot at (781, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 367: Red dot at (783, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 368: Red dot at (785, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 369: Red dot at (787, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 370: Red dot at (790, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 371: Red dot at (792, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 372: Red dot at (794, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 373: Red dot at (796, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 374: Red dot at (798, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 375: Red dot at (800, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 376: Red dot at (802, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 377: Red dot at (804, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 378: Red dot at (807, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 379: Red dot at (809, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 380: Red dot at (811, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 381: Red dot at (813, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 382: Red dot at (815, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 383: Red dot at (817, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 384: Red dot at (819, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 385: Red dot at (822, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 386: Red dot at (824, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 387: Red dot at (826, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 388: Red dot at (828, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 389: Red dot at (830, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 390: Red dot at (832, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 391: Red dot at (834, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 392: Red dot at (837, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 393: Red dot at (839, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 394: Red dot at (841, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 395: Red dot at (843, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 396: Red dot at (845, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 397: Red dot at (847, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 398: Red dot at (849, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 399: Red dot at (851, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 400: Red dot at (854, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 401: Red dot at (856, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 402: Red dot at (858, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 403: Red dot at (860, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 404: Red dot at (862, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 405: Red dot at (864, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 406: Red dot at (866, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 407: Red dot at (869, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 408: Red dot at (871, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 409: Red dot at (873, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 410: Red dot at (875, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 411: Red dot at (877, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 412: Red dot at (879, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 413: Red dot at (881, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 414: Red dot at (883, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 415: Red dot at (886, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 416: Red dot at (888, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 417: Red dot at (890, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 418: Red dot at (892, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 419: Red dot at (894, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 420: Red dot at (896, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 421: Red dot at (898, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 422: Red dot at (901, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 423: Red dot at (903, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 424: Red dot at (905, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 425: Red dot at (907, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 426: Red dot at (909, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 427: Red dot at (911, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 428: Red dot at (913, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 429: Red dot at (916, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 430: Red dot at (918, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 431: Red dot at (920, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 432: Red dot at (922, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 433: Red dot at (924, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 434: Red dot at (926, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 435: Red dot at (928, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 436: Red dot at (930, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 437: Red dot at (933, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 438: Red dot at (935, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 439: Red dot at (937, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 440: Red dot at (939, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 441: Red dot at (941, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 442: Red dot at (943, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 443: Red dot at (945, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 444: Red dot at (948, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 445: Red dot at (950, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 446: Red dot at (952, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 447: Red dot at (954, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 448: Red dot at (956, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 449: Red dot at (958, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 450: Red dot at (960, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 451: Red dot at (962, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 452: Red dot at (965, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 453: Red dot at (967, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 454: Red dot at (969, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 455: Red dot at (971, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 456: Red dot at (973, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 457: Red dot at (975, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 458: Red dot at (977, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 459: Red dot at (980, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 460: Red dot at (982, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 461: Red dot at (984, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 462: Red dot at (986, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 463: Red dot at (988, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 464: Red dot at (990, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 465: Red dot at (992, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 466: Red dot at (995, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 467: Red dot at (997, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 468: Red dot at (999, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 469: Red dot at (1001, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 470: Red dot at (1003, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 471: Red dot at (1005, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 472: Red dot at (1007, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 473: Red dot at (1009, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 474: Red dot at (1012, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 475: Red dot at (1014, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 476: Red dot at (1016, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 477: Red dot at (1018, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 478: Red dot at (1020, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 479: Red dot at (1022, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 480: Red dot at (1024, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 481: Red dot at (1027, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 482: Red dot at (1029, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 483: Red dot at (1031, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 484: Red dot at (1033, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 485: Red dot at (1035, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 486: Red dot at (1037, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 487: Red dot at (1039, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 488: Red dot at (1041, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 489: Red dot at (1044, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 490: Red dot at (1046, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 491: Red dot at (1048, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 492: Red dot at (1050, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 493: Red dot at (1052, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 494: Red dot at (1054, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 495: Red dot at (1056, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 496: Red dot at (1059, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 497: Red dot at (1061, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 498: Red dot at (1063, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 499: Red dot at (1065, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 500: Red dot at (1067, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 501: Red dot at (1069, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 502: Red dot at (1071, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 503: Red dot at (1074, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 504: Red dot at (1076, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 505: Red dot at (1078, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 506: Red dot at (1080, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 507: Red dot at (1082, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 508: Red dot at (1084, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 509: Red dot at (1086, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 510: Red dot at (1088, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 511: Red dot at (1091, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 512: Red dot at (1093, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 513: Red dot at (1095, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 514: Red dot at (1097, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 515: Red dot at (1099, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 516: Red dot at (1101, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 517: Red dot at (1103, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 518: Red dot at (1106, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 519: Red dot at (1108, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 520: Red dot at (1110, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 521: Red dot at (1112, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 522: Red dot at (1114, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 523: Red dot at (1116, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 524: Red dot at (1118, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 525: Red dot at (1120, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 526: Red dot at (1123, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 527: Red dot at (1125, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 528: Red dot at (1127, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 529: Red dot at (1129, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 530: Red dot at (1131, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 531: Red dot at (1133, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 532: Red dot at (1135, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 533: Red dot at (1138, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 534: Red dot at (1140, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 535: Red dot at (1142, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 536: Red dot at (1144, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 537: Red dot at (1146, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 538: Red dot at (1148, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 539: Red dot at (1150, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 540: Red dot at (1153, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 541: Red dot at (1155, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 542: Red dot at (1157, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 543: Red dot at (1159, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 544: Red dot at (1161, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 545: Red dot at (1163, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 546: Red dot at (1165, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 547: Red dot at (1167, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 548: Red dot at (1170, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 549: Red dot at (1172, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 550: Red dot at (1174, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 551: Red dot at (1176, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 552: Red dot at (1178, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 553: Red dot at (1180, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 554: Red dot at (1182, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 555: Red dot at (1185, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 556: Red dot at (1187, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 557: Red dot at (1189, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 558: Red dot at (1191, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 559: Red dot at (1193, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 560: Red dot at (1195, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 561: Red dot at (1197, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 562: Red dot at (1199, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 563: Red dot at (1202, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 564: Red dot at (1204, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 565: Red dot at (1206, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 566: Red dot at (1208, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 567: Red dot at (1210, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 568: Red dot at (1212, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 569: Red dot at (1214, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 570: Red dot at (1217, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 571: Red dot at (1219, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 572: Red dot at (1221, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 573: Red dot at (1223, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 574: Red dot at (1225, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 575: Red dot at (1227, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 576: Red dot at (1229, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 577: Red dot at (1232, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 578: Red dot at (1234, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 579: Red dot at (1236, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 580: Red dot at (1238, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 581: Red dot at (1240, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 582: Red dot at (1242, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 583: Red dot at (1244, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 584: Red dot at (1246, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 585: Red dot at (1249, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 586: Red dot at (1251, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 587: Red dot at (1253, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 588: Red dot at (1255, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 589: Red dot at (1257, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 590: Red dot at (1259, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 591: Red dot at (1261, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 592: Red dot at (1264, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 593: Red dot at (1266, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 594: Red dot at (1268, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 595: Red dot at (1270, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 596: Red dot at (1272, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 597: Red dot at (1274, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 598: Red dot at (1276, 360) with BGR value [  0   0 255]\n",
      "Processed Frame 599: Red dot at (1279, 360) with BGR value [  0   0 255]\n",
      "Processed 600 frames.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Paths (adjust these as per your directory structure)\n",
    "original_video_path = os.path.join(os.getcwd(), 'attachment', 'sample-renamed.mp4')\n",
    "low_fps_video_path = os.path.join(os.getcwd(), 'data', 'video_low_fps.mp4')\n",
    "\n",
    "# Initialize video capture\n",
    "videoCapture = cv2.VideoCapture(original_video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not videoCapture.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get original FPS and frame count\n",
    "fps = videoCapture.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(videoCapture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f'Original FPS: {fps}')\n",
    "print(f'Total Frames: {frame_count}')\n",
    "\n",
    "# Calculate new FPS (reduce by taking every 3rd frame)\n",
    "new_fps = fps / 3\n",
    "print(f'New FPS: {new_fps}')\n",
    "\n",
    "# Define frame size\n",
    "frame_size = (1280, 720)  # (width, height)\n",
    "\n",
    "# Initialize video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
    "output = cv2.VideoWriter(low_fps_video_path, fourcc, new_fps, frame_size, isColor=True)\n",
    "\n",
    "if not output.isOpened():\n",
    "    print(\"Error: Could not open video writer.\")\n",
    "    videoCapture.release()\n",
    "    exit()\n",
    "\n",
    "frame_index = 0\n",
    "processed_frame_num = 0  # To track the number of frames being written\n",
    "\n",
    "# Calculate step for moving the dot across frames\n",
    "# The dot should move from left (0) to right (frame_size[0]-1) over all processed frames\n",
    "if frame_count // 3 > 1:\n",
    "    step = (frame_size[0] - 1) / (frame_count // 3 - 1)\n",
    "else:\n",
    "    step = 0  # Avoid division by zero if only one frame is processed\n",
    "\n",
    "while True:\n",
    "    ret, frame = videoCapture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Process every 3rd frame\n",
    "    if frame_index % 3 == 0:\n",
    "        # Resize to 1280x720\n",
    "        resized_frame = cv2.resize(frame, frame_size)\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Convert grayscale back to BGR (to maintain 3 channels)\n",
    "        bgr_frame = cv2.cvtColor(gray_frame, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Calculate the position of the red dot\n",
    "        x = int(processed_frame_num * step)\n",
    "        y = frame_size[1] // 2  # Center row (height)\n",
    "\n",
    "        # Ensure x is within bounds\n",
    "        x = min(x, frame_size[0] - 1)\n",
    "\n",
    "        # Add the red dot manually\n",
    "        # OpenCV uses BGR, so Red is [0, 0, 255]\n",
    "        bgr_frame[y, x] = [0, 0, 255]\n",
    "        \n",
    "        # Or Easier one for displaying the dot\n",
    "        # cv2.circle(bgr_frame, (x, y), 100, (0, 0, 255), -1)  # Increased radius to 10\n",
    "\n",
    "        # Make the dot larger for visibility\n",
    "        # Define the size of the dot\n",
    "        dot_radius = 10\n",
    "        for dy in range(-dot_radius, dot_radius + 1):\n",
    "            for dx in range(-dot_radius, dot_radius + 1):\n",
    "                if dx**2 + dy**2 <= dot_radius**2:\n",
    "                    nx, ny = x + dx, y + dy\n",
    "                    if 0 <= nx < frame_size[0] and 0 <= ny < frame_size[1]:\n",
    "                        bgr_frame[ny, nx] = [0, 0, 255]\n",
    "\n",
    "        # Debug: Print the RGB value of the dot\n",
    "        print(f'Processed Frame {processed_frame_num}: Red dot at ({x}, {y}) with BGR value {bgr_frame[y, x]}')\n",
    "\n",
    "        # Write the frame to the output video\n",
    "        output.write(bgr_frame)\n",
    "\n",
    "        processed_frame_num += 1\n",
    "\n",
    "    frame_index += 1\n",
    "\n",
    "print(f'Processed {processed_frame_num} frames.')\n",
    "\n",
    "# Release resources\n",
    "videoCapture.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_fps_video_path = os.path.join(os.getcwd(), 'data', 'video_low_fps.mp4')\n",
    "\n",
    "cap = cv2.VideoCapture(low_fps_video_path)\n",
    "frames= []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frames.append(frame)\n",
    "\n",
    "frames_array = np.array(frames)\n",
    "cap.release()\n",
    "\n",
    "print(f\"Shape of frames_array: {frames_array.shape}\")\n",
    "\n",
    "# Extract R, G, B channels\n",
    "r_channel, g_channel, b_channel = frames_array[:, :, 0], frames_array[:, :, 1], frames_array[:, :, 2]\n",
    "\n",
    "# Check if all channels are identical\n",
    "print(np.array_equal(r_channel, g_channel))  # Should be True for grayscale content\n",
    "print(np.array_equal(g_channel, b_channel))  # Should also be True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print length of a  frame\n",
    "print(f\"Length of a frame: {frames_array[0].shape}\")\n",
    "\n",
    "## Print rgb value of this frame\n",
    "print(f\"RGB value of the frame: {frames_array[0][3]}\")\n",
    "\n",
    "single_img = frames_array[200].copy()\n",
    "single_img = cv2.cvtColor(single_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(single_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "Video yang digunakan mempunyai durasi 60 detik dengan 30 fps.\n",
    "Karena akan di ambil setiap frame setiap 3 gambar, maka idealnya proses fps akan berkurang menjadi $\\frac{30}{3} = 10$ fps. Dan memang hasil akhir video menunjukan 10 fps.\n",
    "\n",
    "Untuk grayscale sendiri saya baru tahu, bahwasannya proses konversi dari RGB / BGR ke Grayscale dan sebaliknya hanya untuk menambah / menghapus 3 chanel warna dari sebuah frame video.\n",
    "\n",
    "Informasi mengenai nilai RGB frame sebelumnya sudah hilang ketika dilakukan konversi dari RGB ke Grayscale, nilai grayscale tersebut akan tetap sama meskipun di konversi balik menjadi format RGB / BGR, hanya saja terdapat 3 chanel warna yang ditambahkan.\n",
    "\n",
    "Setelah menambahkan 3 chanel warna, kita dapat melakukan proses penambahan titik pada pixel dan amplifikasi frame tersebut sehingga dapat terlihat dengan mudah di layar.\n",
    "```python\n",
    "    # Calculate the position of the red dot\n",
    "    x = int(processed_frame_num * step)\n",
    "    y = frame_size[1] // 2  # Center row (height)\n",
    "\n",
    "    # Ensure x is within bounds\n",
    "    x = min(x, frame_size[0] - 1)\n",
    "\n",
    "    # Add the red dot manually\n",
    "    # OpenCV uses BGR, so Red is [0, 0, 255]\n",
    "    bgr_frame[y, x] = [0, 0, 255]\n",
    "```\n",
    "Proses ini akan menghitung posisi dari titik merah berdasarkan frame (karena kita membagi frame menjadi setiap 3 frame, maka red dot akan di gambar pada setiap 3 frame tersbut, lalu bergerak ke kanan).\n",
    "\n",
    "Di sisi lain, dot merah ini masih terlalu kecil, maka akan dilakukan amplifikasi untuk menambah ukuran dari dot tersebut.\n",
    "```python\n",
    "dot_radius = 5\n",
    "for dy in range(-dot_radius, dot_radius + 1):\n",
    "    for dx in range(-dot_radius, dot_radius + 1):\n",
    "        if dx**2 + dy**2 <= dot_radius**2:\n",
    "            nx, ny = x + dx, y + dy\n",
    "            if 0 <= nx < frame_size[0] and 0 <= ny < frame_size[1]:\n",
    "                bgr_frame[ny, nx] = [0, 0, 255]\n",
    "```\n",
    "Proses disini cukup sederhana, dot tersebut akan di amplifikasikan untuk setiap panjang dan lebar dari dot tersebut lalu di masukan ke frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deteksi DLIB\n",
    "Using dlib for Detecting faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moving the frame video into nuympy array\n",
    "video_path = os.path.join(os.getcwd(), 'attachment', 'sample-renamed.mp4')\n",
    "\n",
    "videoCapture = cv2.VideoCapture(video_path)\n",
    "video_frames = []\n",
    "\n",
    "## Adding the frames to the video_frames list\n",
    "while True:\n",
    "    ret, frame = videoCapture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    ## Converting into RGB value\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    video_frames.append(frame)\n",
    "\n",
    "frames_array = np.array(video_frames)\n",
    "videoCapture.release()\n",
    "\n",
    "## Print the shape of the frames_array\n",
    "print(f\"Shape of frames_array: {frames_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_img = frames_array[200].copy()\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(single_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection with DLIB\n",
    "using dlib for face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "faces = detector(single_img, 1)\n",
    "for i, face in enumerate(faces): # untuk setiap wajah yang terdeteksi (bisa saja lebih dari satu)\n",
    "    x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "    x2 = x + w\n",
    "    y2 = y + h\n",
    "    cv2.rectangle(single_img, (x, y), (x2, y2), (255, 0, 0), 5)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(single_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling for Hair that not covered?\n",
    "This method handle for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the single image and add the boudiong box to the hair\n",
    "single_img  = frames_array[200].copy()\n",
    "faces = detector(single_img, 1)\n",
    "for i, face in enumerate(faces):\n",
    "    x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "    ## Adding the bounding box to the hair\n",
    "    y_hair = int(y - (0.5 * y))\n",
    "    h_hair = int(h + (0.5 * h))\n",
    "    cv2.rectangle(single_img, (x, y_hair), (x2, h_hair + y_hair), (255, 0, 0), 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show the Bounding box\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(single_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Based on the Face ROI (Region of Interest) and expand for shoulder and chest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain a image and faces detection frame\n",
    "single_img  = frames_array[200].copy()\n",
    "faces = detector(single_img, 1)\n",
    "\n",
    "## Loop through the faces and draw the bounding box\n",
    "for face in faces:\n",
    "    x, y, w, h = (face.left(), face.top(), face.width(), face.height())\n",
    "    \n",
    "    ## Adding the bounding box to the hair\n",
    "    y_hair = int(y - (0.5 * y))\n",
    "    h_hair = int(h + (0.5 * h))\n",
    "    cv2.rectangle(single_img, (x, y_hair), (x2, h_hair + y_hair), (255, 0, 0), 5)\n",
    "\n",
    "        \n",
    "    # Adjust ROI to include shoulders and chest\n",
    "    roi_x = int(x - (0.5 * w))\n",
    "    roi_y = int(y * 2)\n",
    "    roi_w = int(w * 2)\n",
    "    roi_h = int(h * 2.5)  # Adjust the height to include shoulders and chest\n",
    "    \n",
    "    # Ensure the new ROI does not go out of frame bounds\n",
    "    roi_h = min(roi_h, single_img.shape[0] - roi_y)\n",
    "    \n",
    "    # Draw rectangle around the adjusted ROI\n",
    "    cv2.rectangle(single_img, (roi_x, roi_y), (roi_x+roi_w, roi_y+roi_h), (0, 255, 0), 2)\n",
    "\n",
    "# Display the image with the adjusted bounding box\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(single_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "```python\n",
    "## Iteration\n",
    "for i, face in enumerate(faces):\n",
    "```\n",
    "- **`for i, face in enumerate(faces)`**: Ini adalah loop yang akan berjalan sebanyak jumlah wajah yang terdeteksi.\n",
    "  - **`enumerate(faces)`**: `enumerate` memberikan dua nilai untuk setiap iterasi loop: \n",
    "    - `i`: Indeks dari wajah yang terdeteksi (dimulai dari 0).\n",
    "    - `face`: Objek bounding box dari setiap wajah yang terdeteksi. Objek ini memiliki koordinat posisi wajah dalam gambar.\n",
    "\n",
    "```python\n",
    "## Set domain\n",
    "x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "```\n",
    "- **`face.left()`**: Mengambil koordinat x dari tepi kiri kotak pembatas (bounding box) wajah.\n",
    "- **`face.top()`**: Mengambil koordinat y dari tepi atas kotak pembatas wajah.\n",
    "- **`face.width()`**: Mengambil lebar bounding box wajah.\n",
    "- **`face.height()`**: Mengambil tinggi bounding box wajah.\n",
    "- **`x, y, w, h`**: Variabel ini menyimpan posisi dan ukuran dari bounding box wajah yang terdeteksi, di mana:\n",
    "  - `x`: Koordinat x dari sudut kiri atas wajah.\n",
    "  - `y`: Koordinat y dari sudut kiri atas wajah.\n",
    "  - `w`: Lebar bounding box wajah.\n",
    "  - `h`: Tinggi bounding box wajah.\n",
    "\n",
    "```python\n",
    "## Set bouding for width\n",
    "x2 = x + w\n",
    "```\n",
    "- **`x2 = x + w`**: Menghitung koordinat x dari sudut kanan bawah bounding box. Ini didapat dengan menjumlahkan nilai `x` (koordinat kiri atas) dengan `w` (lebar bounding box).\n",
    "\n",
    "```python\n",
    "## Set bouding for height\n",
    "y2 = y + h\n",
    "```\n",
    "- **`y2 = y + h`**: Menghitung koordinat y dari sudut kanan bawah bounding box. Ini didapat dengan menjumlahkan nilai `y` (koordinat kiri atas) dengan `h` (tinggi bounding box).\n",
    "\n",
    "```python\n",
    "## Set bounding box for the face \n",
    "cv2.rectangle(single_img, (x, y), (x2, y2), (255, 0, 0), 5)\n",
    "```\n",
    "- **`cv2.rectangle(single_img, (x, y), (x2, y2), (255, 0, 0), 5)`**:\n",
    "  - Ini menggunakan OpenCV (`cv2`) untuk menggambar kotak persegi panjang (bounding box) di sekitar wajah yang terdeteksi.\n",
    "  - **`single_img`**: Gambar tempat kotak akan digambar.\n",
    "  - **`(x, y)`**: Titik sudut kiri atas dari bounding box (posisi awal persegi).\n",
    "  - **`(x2, y2)`**: Titik sudut kanan bawah dari bounding box (posisi akhir persegi).\n",
    "  - **`(255, 0, 0)`**: Warna persegi panjang dalam format BGR (Biru, Hijau, Merah), di mana (255, 0, 0) berarti biru.\n",
    "  - **`5`**: Ketebalan garis persegi panjang.\n",
    "\n",
    "### Bagian bahu\n",
    "Untuk bagian dada dan bahu, kita dapat melakukan seleksi manual untuk membuat bounding box dengan mendaptkan nilai `x,y,w,h` dari wajah dan kita lakukan proses secara manual untuk membuat bounding box tersebut.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mendeteksi Wajah pada Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Getting the video path dan output path\n",
    "# video_path = os.path.join(os.getcwd(), 'attachment', 'sample-renamed.mp4')\n",
    "# output_path = os.path.join(os.getcwd(), 'data', 'output.mp4')\n",
    "\n",
    "# ## Setting the videoCapture object and its fps\n",
    "# videoCapture = cv2.VideoCapture(video_path)\n",
    "# fps = videoCapture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# ## Setting the frame width and height\n",
    "# frame_width = int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# frame_height = int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# ## Setting the videoWriter object \n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# output = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# ## total_frame_diproses = fps * 5 # 5 detik\n",
    "# frame_count = 0\n",
    "\n",
    "# start_time = dt.datetime.now()\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = videoCapture.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     ## Processes Frame\n",
    "#     faces = detector(frame, 1)\n",
    "#     for face in faces:\n",
    "#         x, y, w, h = (face.left(), face.top(), face.width(), face.height())\n",
    "\n",
    "#         ## Creating a rectangle\n",
    "#         cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 5)\n",
    "#     ## End of Frame Processing\n",
    "\n",
    "#     ## Write the frame to the output video\n",
    "#     output.write(frame)\n",
    "\n",
    "#     frame_count += 1\n",
    "#     if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# print(f\"Waktu yang diperlukan: {dt.datetime.now() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Facial Tracking\n",
    "\n",
    "Using dlib was pain because it takes a long, you can utilize the `facial tracking`. Facial tracking is a tecnique that used for tracking face in a video. \n",
    "\n",
    "With using facial tracking, we can identify face image in every frame video without re-detecting face for every frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "## Setting input and output path\n",
    "video_path = os.path.join(os.getcwd(), 'attachment', 'sample-renamed.mp4')\n",
    "output_path = os.path.join(os.getcwd(), 'data', 'output.mp4')\n",
    "\n",
    "## Setting up the detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "## Setting up the videoCapture object\n",
    "videoCapture = cv2.VideoCapture(video_path)\n",
    "fps = videoCapture.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "## Setting the videoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "## Process frame\n",
    "processed_frame_total = 10 * fps # 10 seconds video processed\n",
    "frame_count = 0\n",
    "\n",
    "## Start time\n",
    "start_time = dt.datetime.now()\n",
    "\n",
    "## Seting up th face detection and re-detect every 3 frames with \n",
    "## Lucas Canade Optical Flow and re-detect the face \n",
    "is_face_detected = False\n",
    "\n",
    "## Initialize points for face tracking and Lucas Canade Optical Flow\n",
    "p0 = None\n",
    "lk_params = dict(winSize=(15, 15),\n",
    "                 maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "## Variabes for face detection\n",
    "detection_interval = fps * 3 # Redetect every 3 seconds\n",
    "detection_countdown = detection_interval\n",
    "\n",
    "## Main Loop\n",
    "while frame_count < processed_frame_total:\n",
    "    ret, frame = videoCapture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    ## Converting to grayscale for easier processing\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ## Check for first frame or re-detect face frame\n",
    "    if frame_count == 0 or detection_countdown == 0:\n",
    "        \n",
    "        ## Check the face detection and if valid face\n",
    "        faces = detector(frame, 1)\n",
    "        if faces:\n",
    "            face = faces[0]\n",
    "            x, y, w, h = (face.left(), face.top(), face.width(), face.height())\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "            ## Get the initial tracking points\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "            ## Initial keypoints detected in the face ROI.\n",
    "            p0 = cv2.goodFeaturesToTrack(face_roi, maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)    \n",
    "\n",
    "            ## Why Adjust the Coordinates?\n",
    "            ## Keypoints detected in the cropped face ROI (face_roi) have coordinates relative to the cropped image, not the full frame. Adding x and y shifts their positions to match the full frames coordinate system:\n",
    "            p0[:, :, 0] += x  # Adjust the x-coordinates\n",
    "            p0[:, :, 1] += y  # Adjust the y-coordinates\n",
    "\n",
    "            ## Reset the detection countdown\n",
    "            is_face_detected = True\n",
    "            detection_countdown = detection_interval\n",
    "    \n",
    "    ## Else using optical flow to track the face\n",
    "    else:\n",
    "        if is_face_detected and p0 is not None:\n",
    "\n",
    "            ## Perform the optical flow with Lucas-Kanade method\n",
    "            ## Optical flow estimates how pixels move from one frame to the next in a video. It tracks the movement of specific points between frames.\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, p0, None, **lk_params)\n",
    "            \n",
    "            good_new = p1[st == 1]  # Successfully tracked keypoints in the current frame.\n",
    "            good_old = p0[st == 1]  # Corresponding keypoints from the previous frame.\n",
    "\n",
    "            ## Calculates the median shift (movement) of the keypoints in both the x and y directions.\n",
    "            if len(good_new) > 1:\n",
    "                x_shift = np.median(good_new[:, 0] - good_old[:, 0])\n",
    "                y_shift = np.median(good_new[:, 1] - good_old[:, 1])\n",
    "\n",
    "                x = int(x + x_shift)\n",
    "                y = int(y + y_shift)\n",
    "\n",
    "                ## Ensure the bouding box remains within the frame\n",
    "                x = max(0, min(x, frame_width - w))\n",
    "                y = max(0, min(y, frame_height - h))\n",
    "\n",
    "                ## Draw the rectangle around the tracked face\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "            # Update the tracking points for the next frame\n",
    "            p0 = good_new.reshape(-1, 1, 2)\n",
    "    \n",
    "    # Write the processed frame to the output video\n",
    "    output.write(frame)\n",
    "\n",
    "    ## Update the previsous frame for optical flow in the next iteration\n",
    "    prev_gray = gray.copy()\n",
    "\n",
    "    ## Update the frame count and detection countdown\n",
    "    frame_count += 1\n",
    "    detection_countdown -= 1\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "## Release the resources\n",
    "videoCapture.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Time taken: {dt.datetime.now() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial Tracking for Seconds 25 - 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0:01:33.353214\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "## Setting input and output path\n",
    "video_path = os.path.join(os.getcwd(), 'attachment', 'sample-renamed.mp4')\n",
    "output_path = os.path.join(os.getcwd(), 'data', 'output.mp4')\n",
    "\n",
    "## Setting up the detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "## Setting up the videoCapture object\n",
    "videoCapture = cv2.VideoCapture(video_path)\n",
    "fps = videoCapture.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "## Setting the videoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "## Process frame\n",
    "processed_frame_total = 10 * fps # 10 seconds video processed\n",
    "frame_count = 0\n",
    "\n",
    "# Calculate frame range for 25 to 40 seconds\n",
    "start_frame = 25 * fps\n",
    "end_frame = 40 * fps\n",
    "\n",
    "## Start time\n",
    "start_time = dt.datetime.now()\n",
    "\n",
    "## Seting up th face detection and re-detect every 3 frames with \n",
    "## Lucas Canade Optical Flow and re-detect the face \n",
    "is_face_detected = False\n",
    "\n",
    "## Initialize points for face tracking and Lucas Canade Optical Flow\n",
    "p0 = None\n",
    "lk_params = dict(winSize=(15, 15),\n",
    "                 maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "## Variabes for face detection\n",
    "detection_interval = fps * 3 # Redetect every 3 seconds\n",
    "detection_countdown = detection_interval\n",
    "\n",
    "## Main Loop\n",
    "while True:\n",
    "    ret, frame = videoCapture.read()\n",
    "    if not ret or frame_count > end_frame:\n",
    "        break\n",
    "\n",
    "    if frame_count >= start_frame:\n",
    "\n",
    "        ## Converting to grayscale for easier processing\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ## Check for first frame or re-detect face frame\n",
    "        if frame_count == 0 or detection_countdown == 0:\n",
    "            \n",
    "            ## Check the face detection and if valid face\n",
    "            faces = detector(frame, 1)\n",
    "            if faces:\n",
    "                face = faces[0]\n",
    "                x, y, w, h = (face.left(), face.top(), face.width(), face.height())\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "                ## Get the initial tracking points\n",
    "                face_roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "                ## Initial keypoints detected in the face ROI.\n",
    "                p0 = cv2.goodFeaturesToTrack(face_roi, maxCorners=60,\n",
    "                                         qualityLevel=0.15,\n",
    "                                         minDistance=3,\n",
    "                                         blockSize=7)    \n",
    "\n",
    "                ## Why Adjust the Coordinates?\n",
    "                ## Keypoints detected in the cropped face ROI (face_roi) have coordinates relative to the cropped image, not the full frame. Adding x and y shifts their positions to match the full frames coordinate system:\n",
    "                p0[:, :, 0] += x  # Adjust the x-coordinates\n",
    "                p0[:, :, 1] += y  # Adjust the y-coordinates\n",
    "\n",
    "                ## Reset the detection countdown\n",
    "                is_face_detected = True\n",
    "                detection_countdown = detection_interval\n",
    "        \n",
    "        ## Else using optical flow to track the face\n",
    "        else:\n",
    "            if is_face_detected and p0 is not None:\n",
    "\n",
    "                ## Perform the optical flow with Lucas-Kanade method\n",
    "                ## Optical flow estimates how pixels move from one frame to the next in a video. It tracks the movement of specific points between frames.\n",
    "                p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, p0, None, **lk_params)\n",
    "                \n",
    "                good_new = p1[st == 1]  # Successfully tracked keypoints in the current frame.\n",
    "                good_old = p0[st == 1]  # Corresponding keypoints from the previous frame.\n",
    "\n",
    "                ## Calculates the median shift (movement) of the keypoints in both the x and y directions.\n",
    "                if len(good_new) > 1:\n",
    "                    x_shift = np.median(good_new[:, 0] - good_old[:, 0])\n",
    "                    y_shift = np.median(good_new[:, 1] - good_old[:, 1])\n",
    "\n",
    "                    x = int(x + x_shift)\n",
    "                    y = int(y + y_shift)\n",
    "\n",
    "                    ## Ensure the bouding box remains within the frame\n",
    "                    x = max(0, min(x, frame_width - w))\n",
    "                    y = max(0, min(y, frame_height - h))\n",
    "\n",
    "                    ## Draw the rectangle around the tracked face\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "                # Update the tracking points for the next frame\n",
    "                p0 = good_new.reshape(-1, 1, 2)\n",
    "        \n",
    "        # Write the processed frame to the output video\n",
    "        output.write(frame)\n",
    "\n",
    "        ## Update the previsous frame for optical flow in the next iteration\n",
    "        prev_gray = gray.copy()\n",
    "\n",
    "        detection_countdown -= 1\n",
    "\n",
    "\n",
    "    ## Update the frame count and detection countdown\n",
    "    frame_count += 1\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "## Release the resources\n",
    "videoCapture.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Time taken: {dt.datetime.now() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the DLIB with Camera and with the Shape Predictor Facial Landmark\n",
    "Using WebCam as the source input and using the DLIB and Shape Predictor for working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "\n",
    "# Initialize dlib's face detector and landmark predictor\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "# landmark_predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale (dlib works better on grayscale)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_detector(gray)\n",
    "    \n",
    "    for face in faces:\n",
    "        # Draw a rectangle around the face\n",
    "        x, y, w, h = (face.left(), face.top(), face.width(), face.height())\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        # # Detect landmarks\n",
    "        # landmarks = landmark_predictor(gray, face)\n",
    "\n",
    "        # # Loop through each landmark and draw them\n",
    "        # for n in range(68):  # 68 points\n",
    "        #     x = landmarks.part(n).x\n",
    "        #     y = landmarks.part(n).y\n",
    "        #     cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "    # Show the video with landmarks\n",
    "    cv2.imshow(\"Facial Tracking\", frame)\n",
    "\n",
    "    # Break on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other method using tracking failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize dlib's face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get video dimensions\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'XVID'), 20.0, (frame_width, frame_height))\n",
    "\n",
    "# Parameters for Lucas-Kanade Optical Flow\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Process the first frame\n",
    "ret, frame = cap.read()\n",
    "gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Initial detection\n",
    "faces = detector(gray_frame)\n",
    "if len(faces) > 0:\n",
    "    face = faces[0]\n",
    "    bbox_points = np.array([[face.left(), face.top()],\n",
    "                            [face.right(), face.top()],\n",
    "                            [face.right(), face.bottom()],\n",
    "                            [face.left(), face.bottom()]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "else:\n",
    "    print(\"No faces detected!\")\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    exit()\n",
    "\n",
    "old_gray = gray_frame\n",
    "\n",
    "# Main loop\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use optical flow to track the bounding box corners\n",
    "    new_points, status, _ = cv2.calcOpticalFlowPyrLK(old_gray, gray_frame, bbox_points, None, **lk_params)\n",
    "\n",
    "    # Check if tracking fails\n",
    "    if np.sum(status) < len(bbox_points) * 0.5:  # Re-detect if less than 50% points are tracked\n",
    "        faces = detector(gray_frame)\n",
    "        if len(faces) > 0:\n",
    "            face = faces[0]\n",
    "            bbox_points = np.array([[face.left(), face.top()],\n",
    "                                    [face.right(), face.top()],\n",
    "                                    [face.right(), face.bottom()],\n",
    "                                    [face.left(), face.bottom()]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "    else:\n",
    "        bbox_points = new_points\n",
    "\n",
    "    # Get the minimum enclosing rectangle for the bounding box points\n",
    "    x, y, w, h = cv2.boundingRect(bbox_points.astype(np.int32))\n",
    "\n",
    "    # Draw the bounding box\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Write the frame to the video file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the video\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    old_gray = gray_frame\n",
    "\n",
    "    # Exit on 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Using the Method with Tracking Failure\n",
    "\n",
    "The first method that redetect the frame every 3 frame is either inefficient to detect if the face are still in the same place, and goes worse if the movement face is suddently and the bounding box is offsetted since the frame is differ (we don't have some temp value for the bounding box).\n",
    "\n",
    "One suggest to using the facial tracking with tracking failure so if the value goes below, we can apply the dlib to ensure the box stay in the face level, it also use the Lucas Canade Optical Flow to check whether the status face detection is valid (1) or not (0) before perfoming the re-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Codebase\n",
    "\n",
    "Firstly, we setup the initial detection with dlib for our initial bounding box.\n",
    "\n",
    "Next, we use the Lucas Canade Optical Flow to check the next frame is still on the face level for our tracking\n",
    "```python\n",
    "# Use optical flow to track the bounding box corners\n",
    "new_points, status, _ = cv2.calcOpticalFlowPyrLK(old_gray, gray_frame, bbox_points, None, **lk_params)\n",
    "```\n",
    "This method returns our new_points and the status value, if our status is 1 tracking is success and 0 for failure, we can use this status value as a condition for doing the re-detection\n",
    "```python\n",
    "# Check if tracking fails\n",
    "if np.sum(status) < len(bbox_points) * 0.5:  # Re-detect if less than 50% points are tracked\n",
    "    faces = detector(gray_frame)\n",
    "    if len(faces) > 0:\n",
    "        face = faces[0]\n",
    "        bbox_points = np.array([[face.left(), face.top()],\n",
    "                                [face.right(), face.top()],\n",
    "                                [face.right(), face.bottom()],\n",
    "                                [face.left(), face.bottom()]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "else:\n",
    "    bbox_points = new_points\n",
    "```\n",
    "Lastly, we can draw the bounding box.\n",
    "\n",
    "In terms from the Code from the Face Tracking and this, this code was more superior, the ability to dynamically doing the re-detection compare to every 3 frames re-detection is much more efficient and tend to less-error prone. with 3 frames re-detection (When the object is suddenly move, it lost the ground truth and the box was suddenly offset and distrupted).\n",
    "\n",
    "Or else you can use the dlib.correlation_tracker() for object tracking which are more light and fast compare to optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Initialize dlib's face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Initialize video capture\n",
    "VID_PATH = os.path.join(os.getcwd(), 'attachment', 'sample-renamed.mp4')\n",
    "\n",
    "cap = cv2.VideoCapture(VID_PATH)\n",
    "\n",
    "# Get video dimensions\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'XVID'), 30.0, (frame_width, frame_height))\n",
    "\n",
    "# Parameters for Lucas-Kanade Optical Flow\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Process the first frame\n",
    "ret, frame = cap.read()\n",
    "gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Initial detection\n",
    "faces = detector(gray_frame)\n",
    "\n",
    "## If face is detected, make a bounding box, else exit\n",
    "if len(faces) > 0:\n",
    "    face = faces[0]\n",
    "    bbox_points = np.array([[face.left(), face.top()],\n",
    "                            [face.right(), face.top()],\n",
    "                            [face.right(), face.bottom()],\n",
    "                            [face.left(), face.bottom()]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "else:\n",
    "    print(\"No faces detected!\")\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    exit()\n",
    "\n",
    "old_gray = gray_frame\n",
    "\n",
    "# Main loop\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use optical flow to track the bounding box corners\n",
    "    new_points, status, _ = cv2.calcOpticalFlowPyrLK(old_gray, gray_frame, bbox_points, None, **lk_params)\n",
    "\n",
    "    # Check if tracking fails\n",
    "    if np.sum(status) < len(bbox_points) * 0.5:  # Re-detect if less than 50% points are tracked\n",
    "        faces = detector(gray_frame)\n",
    "        if len(faces) > 0:\n",
    "            face = faces[0]\n",
    "            bbox_points = np.array([[face.left(), face.top()],\n",
    "                                    [face.right(), face.top()],\n",
    "                                    [face.right(), face.bottom()],\n",
    "                                    [face.left(), face.bottom()]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "    else:\n",
    "        bbox_points = new_points\n",
    "\n",
    "    # Get the minimum enclosing rectangle for the bounding box points\n",
    "    x, y, w, h = cv2.boundingRect(bbox_points.astype(np.int32))\n",
    "\n",
    "    # Draw the bounding box\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Write the frame to the video file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the video\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    old_gray = gray_frame\n",
    "\n",
    "    # Exit on 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Method for Tracking\n",
    "Or you can use the dlib.correlation_tracker(), a built in method for tracking object (for this case face), it was much lighter and faster compare to the optical flow, but I guess this is was an idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "\n",
    "# Initialize video capture and dlib components\n",
    "VID_PATH = os.path.join(os.getcwd(), 'attachment', 'sample-renamed.mp4')\n",
    "\n",
    "cap = cv2.VideoCapture(VID_PATH)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "tracker = dlib.correlation_tracker()\n",
    "\n",
    "initialized = False  # To check if tracking has started\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if not initialized:\n",
    "        # Detect the face\n",
    "        faces = detector(gray)\n",
    "        if len(faces) > 0:\n",
    "            # Initialize the tracker with the first detected face\n",
    "            tracker.start_track(frame, dlib.rectangle(\n",
    "                faces[0].left(), faces[0].top(),\n",
    "                faces[0].right(), faces[0].bottom()\n",
    "            ))\n",
    "            initialized = True\n",
    "    else:\n",
    "        # Update the tracker\n",
    "        tracker.update(frame)\n",
    "        pos = tracker.get_position()\n",
    "\n",
    "        # Get the coordinates of the tracked region\n",
    "        x1, y1, x2, y2 = int(pos.left()), int(pos.top()), int(pos.right()), int(pos.bottom())\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: \n",
    "- [1](https://pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/)\n",
    "- [2](https://www.youtube.com/watch?v=6wMoHgpVUn8)\n",
    "- [3](https://chatgpt.com/share/6745671f-2b68-800c-a771-1aa674644e83)\n",
    "- [4](https://chatgpt.com/c/67466eb4-1f78-800c-a440-426e349d7dc7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_multimedia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
